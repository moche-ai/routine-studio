"""í€„ë¦¬í‹° ì²´ì»¤ ì—ì´ì „íŠ¸ - ë¡œì»¬/Gemini/Qwen ì„¸ ê°€ì§€ ë²„ì „"""
from agents.config import agent_settings

import sys
import json
import subprocess
import base64
import tempfile
from typing import Dict, Any, List, Optional
from pathlib import Path
from enum import Enum
from dataclasses import dataclass
from PIL import Image
import numpy as np
import httpx

sys.path.insert(0, "/app")

from agents.base import BaseAgent, AgentResult, AgentStatus


class CheckerMode(Enum):
    LOCAL = "local"      # ë¡œì»¬ ë¶„ì„ (Python ê¸°ë°˜)
    GEMINI = "gemini"    # Google Gemini API ì‚¬ìš©
    QWEN = "qwen"        # Qwen3-VL-30B Instruct (83% accuracy)


@dataclass
class QualityScore:
    """í’ˆì§ˆ ì ìˆ˜ ë°ì´í„°"""
    overall: float
    details: Dict[str, float]
    issues: List[str]
    suggestions: List[str]
    summary: str


class LocalQualityChecker:
    """ë¡œì»¬ í’ˆì§ˆ ì²´ì»¤ (Python/NumPy ê¸°ë°˜)"""

    def analyze_image(self, image_path: str) -> Dict[str, Any]:
        """ì´ë¯¸ì§€ í’ˆì§ˆ ë¶„ì„"""
        img = Image.open(image_path)
        arr = np.array(img)

        height, width = arr.shape[:2]
        mean_rgb = arr.mean(axis=(0, 1))[:3].astype(int)

        white_pixels = np.sum(np.all(arr > 240, axis=2))
        total_pixels = height * width
        white_ratio = white_pixels / total_pixels * 100

        black_pixels = np.sum(np.all(arr < 30, axis=2))
        black_ratio = black_pixels / total_pixels * 100

        color_std = arr.std()

        issues = []
        suggestions = []

        if white_ratio > 70:
            white_score = 2
            issues.append(f"í°ìƒ‰ ë¹„ìœ¨ì´ ë„ˆë¬´ ë†’ìŒ ({white_ratio:.1f}%)")
            suggestions.append("ìºë¦­í„°ê°€ ë” í¬ê²Œ ê·¸ë ¤ì ¸ì•¼ í•¨")
        elif white_ratio > 50:
            white_score = 5
            issues.append(f"ë°°ê²½ ë¹„ìœ¨ì´ ë†’ìŒ ({white_ratio:.1f}%)")
        elif white_ratio > 30:
            white_score = 7
        else:
            white_score = 9

        if black_ratio < 1:
            outline_score = 5
            issues.append("ì™¸ê³½ì„ ì´ ì•½í•¨")
            suggestions.append("ë” êµµì€ ì™¸ê³½ì„  ì¶”ê°€ í•„ìš”")
        elif black_ratio < 3:
            outline_score = 7
        else:
            outline_score = 9

        if color_std < 30:
            color_score = 4
            issues.append("ìƒ‰ìƒì´ ë‹¨ì¡°ë¡œì›€")
        elif color_std < 50:
            color_score = 6
        else:
            color_score = 8

        if width < 512 or height < 512:
            resolution_score = 5
            issues.append(f"í•´ìƒë„ê°€ ë‚®ìŒ ({width}x{height})")
        elif width >= 1024 and height >= 1024:
            resolution_score = 9
        else:
            resolution_score = 7

        overall = (white_score + outline_score + color_score + resolution_score) / 4

        return {
            "overall_score": round(overall, 1),
            "composition_score": round(white_score, 1),
            "color_quality": round(color_score, 1),
            "character_visibility": round(10 - white_ratio/10, 1),
            "background_cleanliness": round(min(10, white_ratio/5), 1),
            "style_consistency": round(outline_score, 1),
            "issues": issues,
            "suggestions": suggestions,
            "summary": f"ì „ì²´ ì ìˆ˜ {overall:.1f}/10, í°ìƒ‰ {white_ratio:.1f}%, ì™¸ê³½ì„  {black_ratio:.1f}%",
            "stats": {
                "resolution": f"{width}x{height}",
                "mean_rgb": tuple(mean_rgb),
                "white_ratio": round(white_ratio, 1),
                "black_ratio": round(black_ratio, 1),
                "color_std": round(color_std, 1)
            }
        }

    def analyze_video(self, video_path: str, num_frames: int = 5) -> Dict[str, Any]:
        """ë¹„ë””ì˜¤ í’ˆì§ˆ ë¶„ì„ (í”½ì…€ ê¸°ë°˜)"""
        path = Path(video_path)
        if not path.exists():
            return {"error": f"Video not found: {video_path}"}

        frame_results = []

        with tempfile.TemporaryDirectory() as tmpdir:
            cmd = [
                "ffmpeg", "-i", str(path),
                "-vf", f"select=not(mod(n\\,8))",
                "-vframes", str(num_frames),
                "-vsync", "vfr",
                f"{tmpdir}/frame_%03d.png"
            ]
            subprocess.run(cmd, capture_output=True)

            for frame_file in sorted(Path(tmpdir).glob("frame_*.png")):
                img = Image.open(frame_file)
                arr = np.array(img)

                mean_rgb = arr.mean(axis=(0, 1))[:3].astype(int)
                white_ratio = np.sum(np.all(arr > 240, axis=2)) / (arr.shape[0] * arr.shape[1]) * 100

                frame_results.append({
                    "mean_rgb": tuple(mean_rgb),
                    "white_ratio": round(white_ratio, 1)
                })

        if not frame_results:
            return {"error": "í”„ë ˆì„ ì¶”ì¶œ ì‹¤íŒ¨"}

        white_ratios = [f["white_ratio"] for f in frame_results]
        rgb_values = [f["mean_rgb"] for f in frame_results]

        avg_white = np.mean(white_ratios)
        white_variance = np.std(white_ratios)

        rgb_changes = []
        for i in range(1, len(rgb_values)):
            change = np.sqrt(sum((a - b) ** 2 for a, b in zip(rgb_values[i], rgb_values[i-1])))
            rgb_changes.append(change)
        avg_rgb_change = np.mean(rgb_changes) if rgb_changes else 0

        issues = []
        suggestions = []

        if avg_white > 50:
            issues.append(f"í‰ê·  í°ìƒ‰ ë¹„ìœ¨ì´ ë†’ìŒ ({avg_white:.1f}%)")
            suggestions.append("ìºë¦­í„° ìƒ‰ìƒì´ ì œëŒ€ë¡œ ìƒì„±ë˜ì§€ ì•ŠìŒ")
            color_score = 3
        elif avg_white > 20:
            issues.append(f"í°ìƒ‰ ë¹„ìœ¨ì´ ë‹¤ì†Œ ë†’ìŒ ({avg_white:.1f}%)")
            color_score = 6
        else:
            color_score = 8

        if white_variance > 20:
            issues.append("í”„ë ˆì„ ê°„ ì¼ê´€ì„± ë¶€ì¡±")
            consistency_score = 4
        elif white_variance > 10:
            consistency_score = 6
        else:
            consistency_score = 8

        if avg_rgb_change < 5:
            issues.append("ëª¨ì…˜ì´ ê±°ì˜ ì—†ìŒ (ì •ì ì¸ ì˜ìƒ)")
            motion_score = 5
        elif avg_rgb_change > 50:
            issues.append("ëª¨ì…˜ì´ ë„ˆë¬´ ê¸‰ê²©í•¨")
            motion_score = 5
        else:
            motion_score = 8

        overall = (color_score + consistency_score + motion_score) / 3

        return {
            "overall_score": round(overall, 1),
            "motion_quality": round(motion_score, 1),
            "frame_consistency": round(consistency_score, 1),
            "character_preservation": round(10 - avg_white/10, 1),
            "color_stability": round(color_score, 1),
            "artifacts": round(10 - white_variance/5, 1),
            "issues": issues,
            "suggestions": suggestions,
            "summary": f"ì „ì²´ ì ìˆ˜ {overall:.1f}/10, í‰ê·  í°ìƒ‰ {avg_white:.1f}%, RGB ë³€í™”ëŸ‰ {avg_rgb_change:.1f}",
            "frame_analysis": frame_results
        }


class QwenQualityChecker:
    """Qwen3-VL-30B Instruct ê¸°ë°˜ í’ˆì§ˆ ì²´ì»¤ (ìºë¦­í„° ì¼ê´€ì„± ë¶„ì„)"""

    def __init__(self, base_url: str = agent_settings.vision_api_url):
        self.base_url = base_url
        self.model = "qwen3-vl-30b-instruct"

    def _load_image_base64(self, path: str) -> str:
        """ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©"""
        with open(path, "rb") as f:
            return base64.b64encode(f.read()).decode()

    def _extract_frames(self, video_path: str, num_frames: int = 4) -> List[str]:
        """ë¹„ë””ì˜¤ì—ì„œ í”„ë ˆì„ ì¶”ì¶œ í›„ ê²½ë¡œ ë°˜í™˜"""
        with tempfile.TemporaryDirectory() as tmpdir:
            subprocess.run([
                "ffmpeg", "-i", video_path,
                "-vf", f"select=not(mod(n\\,10))",
                "-vframes", str(num_frames),
                "-vsync", "vfr",
                f"{tmpdir}/frame_%02d.png", "-y"
            ], capture_output=True)

            frames = sorted(Path(tmpdir).glob("frame_*.png"))
            result = []
            for i, f in enumerate(frames):
                dest = f"/tmp/qc_frame_{i:02d}.png"
                subprocess.run(["cp", str(f), dest])
                result.append(dest)
            return result

    def _extract_json(self, text: str) -> Optional[dict]:
        """ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ"""
        import re
        matches = re.findall(r'\{[^{}]+\}', text)
        for match in reversed(matches):
            try:
                return json.loads(match)
            except:
                continue
        return None

    async def check_character_consistency(
        self,
        reference_path: str,
        frame_paths: List[str],
        strict: bool = True
    ) -> Dict[str, Any]:
        """ìºë¦­í„° ì¼ê´€ì„± ê²€ì‚¬ (strict_v1 í”„ë¡¬í”„íŠ¸ - 83% ì •í™•ë„)"""

        content = []
        content.append({"type": "text", "text": "REFERENCE (original character):"})
        content.append({
            "type": "image_url",
            "image_url": {"url": f"data:image/png;base64,{self._load_image_base64(reference_path)}"}
        })

        for i, fp in enumerate(frame_paths[:3]):
            content.append({"type": "text", "text": f"FRAME {i+1}:"})
            content.append({
                "type": "image_url",
                "image_url": {"url": f"data:image/png;base64,{self._load_image_base64(fp)}"}
            })

        if strict:
            content.append({"type": "text", "text": """
AI VIDEO QUALITY CHECK - Be STRICT!

This is AI-generated video. AI often FAILS to maintain character consistency.
Look for these COMMON AI FAILURES:

FAIL conditions (score 1-4):
- Face MORPHS or DISTORTS between frames
- Character looks like DIFFERENT PERSON in any frame
- Hair style/color CHANGES
- Body proportions CHANGE
- Skin color/tone CHANGES significantly
- Eyes/nose/mouth shapes CHANGE

PASS conditions (score 8-10):
- EXACT same character in ALL frames
- Face stays IDENTICAL (not just similar)
- No morphing or distortion

Be harsh. Most AI videos FAIL. Output JSON:
{"score": <1-10>, "verdict": "<PASS or FAIL>"}"""})
        else:
            content.append({"type": "text", "text": """
Check if video frames show the same character as reference.
Output JSON: {"score": <1-10>, "verdict": "<PASS or FAIL>"}"""})

        payload = {
            "model": self.model,
            "messages": [{"role": "user", "content": content}],
            "max_tokens": 200,
            "temperature": 0.1,
        }

        try:
            async with httpx.AsyncClient(timeout=120) as client:
                response = await client.post(
                    f"{self.base_url}/chat/completions",
                    json=payload
                )
                result = response.json()

                if "choices" in result:
                    text = result["choices"][0]["message"]["content"]
                    parsed = self._extract_json(text)

                    if parsed:
                        return {
                            "success": True,
                            "score": parsed.get("score"),
                            "verdict": parsed.get("verdict"),
                            "overall_score": parsed.get("score"),
                            "raw_response": text[:300],
                            "issues": ["Character inconsistency detected"] if parsed.get("verdict") == "FAIL" else [],
                            "suggestions": ["Regenerate video with better prompts"] if parsed.get("verdict") == "FAIL" else [],
                            "summary": f"Score: {parsed.get('score')}/10, Verdict: {parsed.get('verdict')}"
                        }
                    return {"success": False, "error": "JSON parse failed", "raw_response": text[:300]}
                return {"success": False, "error": str(result)[:200]}
        except Exception as e:
            return {"success": False, "error": str(e)}

    async def analyze_video(
        self,
        video_path: str,
        reference_path: str,
        num_frames: int = 4
    ) -> Dict[str, Any]:
        """ë¹„ë””ì˜¤ í’ˆì§ˆ ë¶„ì„ (ìºë¦­í„° ì¼ê´€ì„± ê¸°ë°˜)"""
        frame_paths = self._extract_frames(video_path, num_frames)
        if not frame_paths:
            return {"error": "í”„ë ˆì„ ì¶”ì¶œ ì‹¤íŒ¨", "success": False}

        return await self.check_character_consistency(reference_path, frame_paths)


class QualityCheckerAgent(BaseAgent):
    """í€„ë¦¬í‹° ì²´ì»¤ ì—ì´ì „íŠ¸"""

    def __init__(self, mode: CheckerMode = CheckerMode.QWEN):
        super().__init__("QualityCheckerAgent")
        self.mode = mode
        self.local_checker = LocalQualityChecker()
        self.qwen_checker = QwenQualityChecker()
        self._gemini_service = None

    @property
    def gemini_service(self):
        """Gemini ì„œë¹„ìŠ¤ ì§€ì—° ë¡œë”©"""
        if self._gemini_service is None:
            from apps.api.services.gemini import gemini_service
            self._gemini_service = gemini_service
        return self._gemini_service

    async def check_image(self, image_path: str) -> Dict[str, Any]:
        """ì´ë¯¸ì§€ í’ˆì§ˆ ì²´í¬"""
        if self.mode == CheckerMode.LOCAL:
            return self.local_checker.analyze_image(image_path)
        elif self.mode == CheckerMode.QWEN:
            # Qwenì€ ì´ë¯¸ì§€ ë‹¨ë… ë¶„ì„ë„ ê°€ëŠ¥í•˜ì§€ë§Œ ì£¼ë¡œ ë¹„ë””ì˜¤ QCì— ì‚¬ìš©
            return self.local_checker.analyze_image(image_path)
        else:
            return await self.gemini_service.quality_check_image(image_path)

    async def check_video(
        self,
        video_path: str,
        reference_path: str = None
    ) -> Dict[str, Any]:
        """ë¹„ë””ì˜¤ í’ˆì§ˆ ì²´í¬"""
        if self.mode == CheckerMode.LOCAL:
            return self.local_checker.analyze_video(video_path)
        elif self.mode == CheckerMode.QWEN:
            if not reference_path:
                # referenceê°€ ì—†ìœ¼ë©´ LOCAL ë¶„ì„ìœ¼ë¡œ í´ë°±
                return self.local_checker.analyze_video(video_path)
            return await self.qwen_checker.analyze_video(video_path, reference_path)
        else:
            return await self.gemini_service.quality_check_video(video_path)

    async def check_batch(
        self,
        image_paths: List[str] = None,
        video_paths: List[str] = None,
        reference_path: str = None
    ) -> Dict[str, Any]:
        """ë°°ì¹˜ í’ˆì§ˆ ì²´í¬"""
        results = {
            "images": [],
            "videos": [],
            "summary": {}
        }

        if image_paths:
            for path in image_paths:
                result = await self.check_image(path)
                result["path"] = path
                results["images"].append(result)

        if video_paths:
            for path in video_paths:
                result = await self.check_video(path, reference_path)
                result["path"] = path
                results["videos"].append(result)

        if results["images"]:
            scores = [r.get("overall_score", 0) for r in results["images"]]
            results["summary"]["avg_image_score"] = round(sum(scores) / len(scores), 1)
            results["summary"]["best_image"] = results["images"][scores.index(max(scores))]["path"]

        if results["videos"]:
            scores = [r.get("overall_score", 0) or r.get("score", 0) for r in results["videos"]]
            valid_scores = [s for s in scores if s]
            if valid_scores:
                results["summary"]["avg_video_score"] = round(sum(valid_scores) / len(valid_scores), 1)
                results["summary"]["best_video"] = results["videos"][scores.index(max(scores))]["path"]

            # PASS/FAIL í†µê³„
            verdicts = [r.get("verdict") for r in results["videos"] if r.get("verdict")]
            if verdicts:
                results["summary"]["pass_count"] = verdicts.count("PASS")
                results["summary"]["fail_count"] = verdicts.count("FAIL")

        return results

    async def compare_with_gemini(
        self,
        image_paths: List[str] = None,
        video_paths: List[str] = None
    ) -> Dict[str, Any]:
        """Geminië¥¼ ì‚¬ìš©í•œ ê³ ê¸‰ ë¹„êµ ë¶„ì„"""
        return await self.gemini_service.compare_quality(image_paths, video_paths)

    async def execute(self, input_data: Dict[str, Any]) -> AgentResult:
        """ì—ì´ì „íŠ¸ ì‹¤í–‰"""
        self.status = AgentStatus.RUNNING

        image_paths = input_data.get("images", [])
        video_paths = input_data.get("videos", [])
        reference_path = input_data.get("reference")
        use_gemini = input_data.get("use_gemini", False)
        use_qwen = input_data.get("use_qwen", True)  # ê¸°ë³¸ê°’ Qwen

        if use_gemini:
            self.mode = CheckerMode.GEMINI
        elif use_qwen:
            self.mode = CheckerMode.QWEN

        try:
            results = await self.check_batch(image_paths, video_paths, reference_path)

            self.status = AgentStatus.COMPLETED
            return AgentResult(
                success=True,
                step="quality_check",
                message=self._format_results(results),
                needs_feedback=False,
                data=results
            )
        except Exception as e:
            self.status = AgentStatus.ERROR
            return AgentResult(
                success=False,
                step="quality_check",
                message=f"í’ˆì§ˆ ì²´í¬ ì‹¤íŒ¨: {e}",
                needs_feedback=False,
                data={"error": str(e)}
            )

    def _format_results(self, results: Dict[str, Any]) -> str:
        """ê²°ê³¼ í¬ë§·íŒ…"""
        lines = ["# ğŸ“Š í’ˆì§ˆ ì²´í¬ ê²°ê³¼\n"]

        if results.get("images"):
            lines.append("## ì´ë¯¸ì§€ ë¶„ì„\n")
            for img in results["images"]:
                path = Path(img["path"]).name
                score = img.get("overall_score", "N/A")
                lines.append(f"- **{path}**: {score}/10")
                if img.get("issues"):
                    for issue in img["issues"][:2]:
                        lines.append(f"  - {issue}")
            lines.append("")

        if results.get("videos"):
            lines.append("## ë¹„ë””ì˜¤ ë¶„ì„\n")
            for vid in results["videos"]:
                path = Path(vid["path"]).name
                score = vid.get("overall_score") or vid.get("score", "N/A")
                verdict = vid.get("verdict", "")
                verdict_emoji = "" if verdict == "PASS" else "" if verdict == "FAIL" else ""
                lines.append(f"- **{path}**: {score}/10 {verdict_emoji} {verdict}")
                if vid.get("issues"):
                    for issue in vid["issues"][:2]:
                        lines.append(f"  - {issue}")
            lines.append("")

        if results.get("summary"):
            lines.append("## ìš”ì•½\n")
            summary = results["summary"]
            if "avg_image_score" in summary:
                lines.append(f"- í‰ê·  ì´ë¯¸ì§€ ì ìˆ˜: {summary['avg_image_score']}/10")
            if "avg_video_score" in summary:
                lines.append(f"- í‰ê·  ë¹„ë””ì˜¤ ì ìˆ˜: {summary['avg_video_score']}/10")
            if "pass_count" in summary:
                lines.append(f"- PASS: {summary['pass_count']}, FAIL: {summary['fail_count']}")
            if "best_image" in summary:
                lines.append(f"- ìµœê³  ì´ë¯¸ì§€: {Path(summary['best_image']).name}")
            if "best_video" in summary:
                lines.append(f"- ìµœê³  ë¹„ë””ì˜¤: {Path(summary['best_video']).name}")

        return "\n".join(lines)
